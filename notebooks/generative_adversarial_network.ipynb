{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Quick, Draw!\" GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code based directly on [Grant Beyleveld's](https://github.com/grantbey/quickdraw-GAN/blob/master/octopus-v1.0.ipynb), which is derived from [Rowel Atienza's](https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0) under [MIT License](https://github.com/roatienza/Deep-Learning-Experiments/blob/master/LICENSE)\n",
    "* data provided by [Google](https://github.com/googlecreativelab/quickdraw-dataset) under [Creative Commons Attribution 4.0 license](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Activation, Conv2D, Reshape, Dense, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers import UpSampling2D, Conv2DTranspose, AveragePooling2D # new! \n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../quickdraw/rainbow.npy')\n",
    "data = data/255\n",
    "data = np.reshape(data,(data.shape[0],28,28,1))\n",
    "img_w,img_h = data.shape[1:3]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_builder(depth=64,p=0.4):\n",
    "    \n",
    "    # Define inputs\n",
    "    # CODE HERE\n",
    "    \n",
    "    # Convolutional layers\n",
    "    # CODE HERE\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile discriminator: \n",
    "discriminator_model = discriminator_builder()\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_builder(z_dim=100,depth=64,p=0.4):\n",
    "    \n",
    "    # Define inputs\n",
    "    # CODE HERE\n",
    "    \n",
    "    # First dense layer\n",
    "    # CODE HERE\n",
    "    \n",
    "    # Deconvolutional layers\n",
    "    # CODE HERE\n",
    "\n",
    "    # Define output layers\n",
    "    # CODE HERE\n",
    "\n",
    "    # Model definition    \n",
    "    # CODE HERE\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_builder(z_dim=100):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # CODE HERE\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM = adversarial_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = './images'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(epochs=2000,batch=128):\n",
    "    for i in range(epochs):\n",
    "\n",
    "        real_imgs = np.reshape(data[np.random.choice(data.shape[0],batch,replace=False)],(batch,28,28,1))\n",
    "        fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 100]))\n",
    "        \n",
    "        x = np.concatenate((real_imgs,fake_imgs))\n",
    "        y = np.ones([2*batch,1])\n",
    "        y[batch:,:] = 0\n",
    "        \n",
    "        d_loss = discriminator_model.train_on_batch(x,y)\n",
    "        \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch, 100])\n",
    "        y = np.ones([batch,1])\n",
    "        a_loss = AM.train_on_batch(noise,y)\n",
    "                \n",
    "        if (i+1)%1000 == 0:\n",
    "            print('Epoch #{}'.format(i+1))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            plt.figure(figsize=(5,5))\n",
    "            \n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k+1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig('./images/rainbow_{}.png'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
